import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor
import matplotlib.pyplot as plt

df = pd.read_csv('/content/passenger_boarding_dataset.csv', header=1)
print("Data Loaded")

df.columns = [ 'Passenger ID', 'Speed','Age', 'Location','Revenue','Group Size' ,'Carry-on',  'Special Need Status','Distance from Gate' ]
df.drop(columns=[ 'Location' ], inplace=True)
df.fillna(0, inplace=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)

models = {}
for i, target in enumerate(y.columns):
    # Initialize the model
    model = XGBRegressor(n_estimators=100, max_depth=3, random_state=7)

    # Train the model on the current target
    model.fit(X_train, y_train.iloc[:, i])
    models[target] = model

    # Feature Importance
    print(f"Feature Importance for {target}:")
    importance = model.feature_importances_
    for feature, score in zip(X.columns, importance):
        print(f"{feature}: {score:.4f}")


    # Plot Feature Importance
    plt.figure(figsize=(8, 5))
    plt.bar(X.columns, importance, color='skyblue')
    plt.title(f"Feature Importance for {target}")
    plt.ylabel("Importance Score")
    plt.xlabel("Features")
    plt.xticks(rotation=45)
    plt.show()

